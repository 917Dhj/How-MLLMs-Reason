# 调研：如何使多模态大模型具备推理能力？

*我认为这里指的应该是“多模态大语言模型”，因为“推理能力”一般是指在复杂问题中**基于语言进行逻辑、因果、常识、步骤推导**。*

在大模型发展的背景下，多模态大语言模型（Multimodal Large Language Models, MLLMs）被广泛用于处理图像与语言混合输入的复杂任务。然而，目前关于“如何让多模态大模型具备推理能力”的理解仍不清晰。本报告围绕这一核心问题展开调研，试图从结构设计、输入机制到推理过程逐层分析。

## [一、导论：多模态大语言模型的概念](report.md#多模态大模型基础概念)

- [**多模态的概念**](report.md#多模态)
- [**多模态大语言模型（Multimodel Large Language Model）**](report.md#多模态大语言模型（multimodel-large-language-model）)
- [**多模态感知与生成方式**](report.md#多模态感知与生成方式)
- [**多模态大语言模型的通用技术框架**](report.md#多模态大语言模型的通用技术框架)

---

## 二、核心问题：MLLM如何具备推理能力？

我们认为，这一能力的形成过程不是单一模块或技巧决定的，而是建立在以下**三大系统性环节**之上的：

### [1. 感知与对齐（Perception & Alignment）—— 模型是否“看得见”而且“听得懂”](report.md#核心问题：llm如何理解多模态信息？)

MLLM 首先需要具备接收和理解图像等非语言模态信息的能力，这包括两个子步骤：

- **感知阶段**：利用视觉编码器（如 CLIP、ViT）提取图像特征，形成视觉 token
- **对齐阶段**：将视觉 token 映射到语言模型能理解的语义空间，使其作为语言提示词使用

**技术路径包括**：

- [Q-Former：主动提取摘要特征（信息压缩）](report.md#1-q-formerquery-token对齐)
- [Patch Embedding：直接将图像切分为 patch 输入（高保真）](report.md#2-直接patch-embedding)
- [多模态Adapter + Token 映射：轻量转换成语言模型能识别的 token](report.md#3-多模态adapter+token预处理)
- Prompt 工程：将视觉 token 当作语言 prompt 的前缀注入

只有完成这一步，语言模型才有“接收视觉信息”的可能。

### 2. 推理机制（Reasoning）—— 模型是否“能思考”

在完成感知与对齐之后，LLM 实际上已经“看见并听懂了”图像等模态信息。接下来的关键任务，是让语言模型利用这些信息在语义空间中构建逻辑链条，完成真正的推理过程。

#### [LLM是如何实现推理的呢？](report.md#LLM如何实现推理？)

- 首先要明确，在[大模型中，何为推理？](report.md#什么是推理？)
- [LLM实现推理的技术机制是什么？](report.md#纯语言模型推理的技术实现机制)
- [为什么说LLM能推理了，MLLM也就能推理了](report.md#从语言推理任务=>多模态推理)

这些机制综合作用，使模型能在“语言驱动”的前提下实现多模态条件下的逻辑判断。

---

## [三、如何增强MLLM的推理能力？](report.md#如何增强MLLM的推理能力？)

[1. 有监督学习](report.md#1-有监督学习：通过“教它怎么推理”来提升能力)

[2. 上下文学习+Prompt工程](report.md#2-上下文学习（in-context-learning）+-prompt工程)

[3. 外部工具协作](report.md#3-外部工具协作（tool-augmented-reasoning）)

## [四、如何评估MLLM的推理能力？](report.md#多模态推理能力评估基准)

## [五、实验设计：对比不同感知与对齐方式的MLLM的推理能力](resoning_exp.md#实验：对比不同感知与对齐方式的MLLM的推理能力)

