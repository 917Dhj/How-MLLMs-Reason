# 如何使多模态大模型具备推理能力？

*我认为这里指的应该是“多模态大语言模型”，因为“推理能力”一般是指在复杂问题中**基于语言进行逻辑、因果、常识、步骤推导**。*

## 多模态大模型基础概念

### 多模态

**模态**就是信息的形式或类型。多模态大模型就是一种**可以同时理解、处理和生成多种模态信息的大模型**。多模态大模型需要做到的有：

- 看图写文案（图像 → 文本）

- 看图回答问题（图像 + 文本 → 文本）

- 听声音识别场景（音频 → 文本）

- 视频理解（视频 → 总结、描述）

- 跨模态搜索（用文字搜图、用图搜文字）

### [多模态大语言模型（Multimodel Large Language Model）](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)

多模态大模型泛指能处理多种模态（图像、文本、音频）的模型。**多模态大语言模型**是“多模态大模型”的一种，重点是**语言能力更强**。本质是 LLM（大语言模型）加入图像等其他模态处理能力。例如 GPT-4V、Gemini、LLava、MiniGPT-4 等。

> 在构建多模态大语言模型（MLLM）之前，本领域的研究者们都达成了一个共识、一个关键前提：由于规模定律和新兴现象，当前基于语言的LLM已经具有了强大的语义理解能力，这意味着语言已经成为承载智能的关键模态，所以**语言智能被认为是多模态智能的枢纽**。因此，几乎所有的MLLM都是建立在基于语言的LLM之上的，我这LLM作为核心决策模块，类似于大脑或中央处理器。换句话说，<u>**通过添加额外的外部非文本模态模块或编码器，LLM被赋予了多模态感知/操作能力**。</u>

### 多模态感知与生成方式

*这描述了模型在面对多模态输入时的两种不同设计策略*

#### 1. Input-side Perceiving（输入端感知范式）

**核心思想**：模型对多模态信息（图像、音频等）只做“感知/理解”，但不进行直接生成，生成任务由语言模型单独完成。模态信息在输入时就被压缩成与语言对齐的表示（通常是 token），之后交由语言模型完成文本生成。

**输入端感知范式具有如下特点**：

- 模态的内容只出现在输入端
- 图像/音频等模态被编码成embedding或token，接入LLM
- LLM是冻结的，不参与感知建模

**Input-side Perceiving的优点在于**：

- 架构简单，计算效率较高
- 易于在已有LLM上扩展多模态输入
- 模块解耦，便于调试和迁移

**缺点在于**：

- 感知与生成脱节，不易捕捉细粒度交互
- 缺乏深层融合，**推理能力有限**

#### 2. Perceiving + Generating（联合感知与生成范式）

**核心思想**：模型不仅能**感知**多模态输入，还能在整个处理过程中融合这些信息进行**生成与推理**。模型结构通常是**端到端（end-to-end）**，多模态信息在中间层被反复交互使用，影响输出生成过程。

**这种设计思路具有如下特点**：

- 多模态信息参与整个生成过程（不仅是输入）

- Transformer 主体可以同时处理图像 + 文本

- 模型**具备更强的对齐、推理和交互能力**

**其优点如下**：

- 感知与生成紧密结合

- 跨模态推理能力更强

- 更适合复杂任务（如图文推理、多轮对话等）

| **特性** | **Input-side Perceiving** | **Perceiving + Generating** |
| -------- | ------------------------- | --------------------------- |
| 感知方式 | 输入预处理                | 端到端深度融合              |
| 生成策略 | LLM 独立生成              | 多模态参与生成              |
| 模型结构 | 分模块                    | 紧密集成                    |
| 代表模型 | BLIP-2, MiniGPT-4         | GPT-4V, Gemini, LLaVA-2     |
| 推理能力 | 中等                      | 强                          |
| 训练成本 | 较低                      | 较高                        |

### 多模态大语言模型的通用技术框架

*目前社区存在两种常见的MLLM架构*

#### 1. LLM as Task Scheduler（LLM作为调度器）

第一种是“LLM作为离散调度器/控制器”的架构。在这个架构中，LLM的角色是**接收文本信号并向下游模块发出文本命令**。系统内部的所有消息传递都是通过LLM输出的纯文本命令作为媒介进行的。不同的功能模块之间不存在交互。

**打个比方**，LLM是公司的老板，手下有几个员工：小图负责看图、小音负责听音频、小表负责数据分析等...现在老板可以这么做：

**客户要你帮忙看一张图中描绘的是什么事情**，于是：

- 你告诉小图：看一下这张图里有什么，告诉我
- 小图说：这里面是一个人在吃汉堡
- 你收到小图的回答之后，再告诉顾客：“这可能是一个人在吃汉堡，他可能是在快餐店里”

**也就是说，在这个架构下**：

- LLM不理解图像，它只理解外部感知器（图像感知器）反馈的文字
- 所有模块之间**没有直接交流**，都要通过 LLM 来转发
- 信息传递靠“语言指令”和“返回结果”

**这个架构的应用**：

- **[Toolformer](https://arxiv.org/abs/2302.04761)**：LLM 会根据任务决定是否调用工具
- **[ReAct](https://arxiv.org/abs/2210.03629)**：Reasoning + Acting，用 LLM 控制整个流程

#### 2. Encoder——LLM——Decoder（编码器——LLM——解码器）

这也是目前最流行的架构。其中**LLM的角色是感知多模态信息**，并在一个编码器-LLM-解码器的结构中自行做出响应和操作。因此，这个架构跟前一个架构的关键区别在于：LLM作为系统的关键联合部分，直接从外部接收多模态信息，并以更顺畅的方式委派指令给解码器/生成器。在编码器-LLM-解码器框架中，编码器处理来自多个模态的编码信号，LLM充当核心决策者，而解码器管理多模态输出。

![image-20250329141312565](assets/image-20250329141312565.png)

**这次LLM不当老板了，而是亲自参加项目研讨**。LLM身边的同事有：

- 图像编码器（图片->理解语言）
- 你自己LLM（收集各方信息，真正理解并推理）
- 发言人（解码器）：根据你说的，输出最终的答案

**当你收到一个看图的任务时，你们做的是**：

1. 看图（编码器处理）
2. 你自己理解这个图是什么意思（LLM推理）
3. 你自己说话写答案（解码器输出）

**与前一个架构的区别在**：

- LLM **直接接收多模态信息**（比如图片特征、图文token）
- 感知、理解、生成**一体化完成**
- 内部信息流动**顺畅自然**，可以完成更复杂的推理任务

**目前的使用这个架构的模型**：	

- [**GPT-4V**](https://openai.com/gpt-4): 可以“看图+理解+回答问题”

- [**Gemini（Google）**](https://deepmind.google/technologies/gemini/): 真正原生多模态模型

- [**LLaVA-2**](https://llava-vl.github.io/): 用图像编码器 + LLM 微调融合

### LLM是如何理解多模态信息的？

在上面提到的Encoder-LLM-Decoder架构中，LLM需要通过


## 什么是“多模态推理”？



## 当前模型如何实现多模态推理能力？

## 推理能力评估方法

## 当前挑战与研究方向

## 参考文献

https://arxiv.org/pdf/2401.13601

https://arxiv.org/abs/2302.04761

https://arxiv.org/abs/2210.03629
