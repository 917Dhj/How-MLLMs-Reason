| **实验类型**              | **举例**                                     | **能验证什么**           |
| ------------------------- | -------------------------------------------- | ------------------------ |
| ✅ **图文问答实验（VQA）** | 给一张图+一个问题，让 LLaVA 回答             | 模型是否理解图像并能推理 |
| ✅ **对比问答实验**        | 同一张图 + 不同问题，看 LLaVA 是否有差异回答 | 模型是否“看懂细节”       |
| ✅ **图像-无图对照**       | 用图像 + 提问 vs 只用提问，看回答有无差异    | 图像输入是否真正被用到了 |

> 我选择了 LLaVA 多模态模型，采用“Adapter + Token 预处理”的方式对图像输入进行处理。我设计了若干图像-问题对，观察 LLaVA 是否能利用图像信息进行理解与推理。通过与无图输入对比，我验证了视觉 token 确实影响了模型生成的内容，体现了多模态输入对语言推理能力的增强。

| **指标**           | **怎么判断**                                       |
| ------------------ | -------------------------------------------------- |
| 回答是否合理       | 模型回答是否和图像语义一致                         |
| 回答是否详细       | 是否能结合多个图像元素进行描述                     |
| 回答是否有逻辑性   | 是否体现“因果”“条件”“顺序”等推理线索               |
| 和无图回答有啥不同 | 如果只提问不放图，模型能不能回答出内容？（对照组） |